{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Persistent Chroma client\n",
    "client = chromadb.PersistentClient(path=\"/path/chroma_storage_nomic\")\n",
    "\n",
    "def nomic_embed(texts):\n",
    "    \"\"\"Get embeddings from Nomic via Ollama API (single text at a time)\"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    url = \"http://127.0.0.1:11434/api/embeddings\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    embeddings = []\n",
    "\n",
    "    for text in texts:\n",
    "        data = {\n",
    "            \"model\": \"nomic-embed-text:latest\",\n",
    "            \"prompt\": text\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        if response.status_code != 200:\n",
    "            raise ConnectionError(f\"Failed to get embeddings: {response.status_code} {response.text}\")\n",
    "        res_json = response.json()\n",
    "        if \"embedding\" in res_json:\n",
    "            embeddings.append(res_json[\"embedding\"])\n",
    "        else:\n",
    "            raise ValueError(f\"No embedding returned for text: {text}\")\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def recreate_collection(name):\n",
    "    \"\"\"Delete a collection if it exists and recreate it\"\"\"\n",
    "    try:\n",
    "        client.delete_collection(name)\n",
    "        print(f\"🗑️ Deleted existing collection: {name}\")\n",
    "    except Exception:\n",
    "        # Ignore if collection doesn't exist\n",
    "        pass\n",
    "    return client.create_collection(name=name)\n",
    "\n",
    "def load_csv_to_chroma(csv_path, collection, batch_size=50):\n",
    "    \"\"\"Load CSV rows into Chroma with Nomic embeddings\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    docs, ids, metas = [], [], []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        accession = str(row.get(\"Run\", f\"row{i}\"))\n",
    "\n",
    "        # Build full text from ALL columns (key: value)\n",
    "        row_text_parts = []\n",
    "        for col, val in row.items():\n",
    "            if pd.notna(val):  # skip NaN\n",
    "                row_text_parts.append(f\"{col}: {val}\")\n",
    "        text = \"\\n\".join(row_text_parts)\n",
    "\n",
    "        docs.append(text.strip())\n",
    "        ids.append(f\"{accession}_{i}\")\n",
    "        metas.append({\n",
    "            \"accession\": str(row.get(\"Run\",\"\")),  # from Run column\n",
    "            \"gene\": str(row.get(\"GENE\", \"\")),\n",
    "            \"database\": str(row.get(\"DATABASE\", \"\")),\n",
    "            \"resistance\": str(row.get(\"RESISTANCE\", \"\")),\n",
    "            \"collection_date\": str(row.get(\"Collection_Date\", \"\")),\n",
    "            \"country\": str(row.get(\"country\", \"\")),\n",
    "            \"continent\": str(row.get(\"continent\", \"\")),\n",
    "            \"isolation_source\": str(row.get(\"isolation_source\", \"\")),\n",
    "            \"host\": str(row.get(\"HOST\", \"\")),\n",
    "            \"organism\": str(row.get(\"Organism\", \"\")),\n",
    "        })\n",
    "\n",
    "        # Insert in batches\n",
    "        if len(docs) >= batch_size:\n",
    "            embeddings_batch = nomic_embed(docs)\n",
    "            collection.add(documents=docs, ids=ids, metadatas=metas, embeddings=embeddings_batch)\n",
    "            docs, ids, metas = [], [], []\n",
    "\n",
    "    # Insert remaining\n",
    "    if docs:\n",
    "        embeddings_batch = nomic_embed(docs)\n",
    "        collection.add(documents=docs, ids=ids, metadatas=metas, embeddings=embeddings_batch)\n",
    "\n",
    "    # Insert remaining\n",
    "    if docs:\n",
    "        embeddings_batch = nomic_embed(docs)\n",
    "        collection.add(documents=docs, ids=ids, metadatas=metas, embeddings=embeddings_batch)\n",
    "\n",
    "# === Recreate collections ===\n",
    "resfinder_col = recreate_collection(\"resistancefinder\")\n",
    "vfdb_col = recreate_collection(\"virulencedb\")\n",
    "plasmid_col = recreate_collection(\"Plasmidfinder\")\n",
    "mge_col = recreate_collection(\"mge\")\n",
    "\n",
    "# === Load CSVs ===\n",
    "load_csv_to_chroma(\"/path/resfinder_combined.csv\", resfinder_col)\n",
    "load_csv_to_chroma(\"/path/vfdb_combined.csv\", vfdb_col)\n",
    "load_csv_to_chroma(\"/path/plasmidfinder_combined.csv\", plasmid_col)\n",
    "load_csv_to_chroma(\"/path/merged_mge.csv\", mge_col)\n",
    "\n",
    "print(\"✅ All collections rebuilt with Nomic embeddings (old vectors cleared)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
